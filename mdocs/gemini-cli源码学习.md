# 从 Gemini CLI 学习如何开发 AI Agent

## 一、Executive Summary

- **Gemini CLI 是什么**：  
  一个深度集成在本地开发环境的 AI 编码助手 CLI 工具，它把「大模型 + 工具调用 + 工程规范 + 安全回滚」封装成一个可控的 Agent 系统，实质上是一个工程化极强的 AI Agent 标杆实现。

- **为什么对我们有参考价值**：
  - 能否在保证质量和安全前提下，把大量“日常工程劳动”自动化的关键；
  - 能否在企业尺度上 **可控地引入 AI**（规范、权限、审计、回滚）的样板；
  - 能否通过“统一规范 + 统一工具链”，把分散团队的工程实践收敛起来。

- **Gemini CLI 给我们的 5 个关键启示**：
  1. **GEMINI.md：把项目规范变成 Agent 的“长期记忆”**
     - 不只是 README，而是“项目如何写代码、如何测试、如何接入基础设施”的机器可读规范中心。
  2. **Checkpointing：默认不信任 AI，先上安全网再谈效率**
     - 每次允许 AI 改代码前自动做 Git 影子快照 + 记录会话 + 工具调用，支持一键
       `/restore` 回滚。
  3. **企业级治理：策略引擎 + 集中配置 + 审计日志**
     - 通过策略文件限制可用工具、可写目录、网络访问；通过统一 `settings.json`
       管控模型、区域、超时。
  4. **Token 缓存与成本优化：从设计层面控制成本，而不是“事后看账单”**
     - 缓存固定提示、做上下文裁剪、用双模型路由、限制输出，系统性降低 Token 消耗。
  5. **Agent 架构模式选择：不是“多代理越多越好”，而是按场景选型**
     - 单 Agent / Multi-Agent / Manager-Worker /
       Orchestration，不同模式适合不同业务。

---

## 二、Gemini CLI 概览：一个工程化 AI Agent 的样板

从工程视角看，Gemini CLI 本质上是一个：

- **面向开发者的终端 Agent**：通过命令行对话，读取/修改本地代码、运行工具、调用模型；
- **强工程规范驱动的系统**：通过 `GEMINI.md`
  和项目内文档，约束 AI 写代码的风格、质量、测试要求；
- **带有安全回滚机制的自动化改代码机器人**：在每一次写入前自动创建 checkpoint，支持一键恢复；
- **可被企业统一治理的工具链**：通过策略文件、集中配置、影子 Git 仓和日志，实现权限、审计、回滚。

我们可以把它看作：**“未来我们自己做的开发助手/Agent 的参考实现”**。

---

## 三、GEMINI.md：把规范变成 Agent 的“记忆体”和行动约束

### 1. GEMINI.md 的角色：不只是 README，而是“AI 版工程手册”

从现有内容看，`GEMINI.md` 不是普通的项目文档，而是：

- **提交前质量门槛的总览**：
  - 强制执行 `npm run preflight`，一次性跑 `build / test / typecheck / lint`
    四个关。
- **测试规范总览**：
  - 框架统一使用 Vitest；
  - 测试文件 co-locate 在源码旁边；
  - 约定 mock、异步测试、React/Ink 组件测试的写法。
- **TypeScript / JavaScript 风格规范**：
  - 优先 **普通对象 + TS 类型/接口**，避免滥用 class；
  - 严禁 `any`，推荐 `unknown` + 类型缩小；
  - 使用模块导出控制公共 API；
  - 推荐使用数组函数（`map/filter/reduce`）而非命令式循环。
- **React 指南**：
  - 函数组件 + Hooks，避免 class 组件；
  - 渲染逻辑保持纯函数；
  - 正确使用 `useEffect`、依赖项、清理；
  - 避免直接修改 state；
  - 考虑并发兼容，避免滥用 `useMemo`、`useCallback`。
- **其他工程约束**：
  - 使用 `checkExhaustive` 做 `switch` 穷举检查；
  - flag 名统一使用连字符（`--my-flag`）；
  - 只写高价值注释；
  - 文档贡献需遵守 `/docs` 和 `CONTRIBUTING.md` 的规范。

也就是说：**GEMINI.md 是“给 AI 和人都看的工程规范 + 行为提示”**，让 Agent 知道：

1. 这个仓库 “什么样的代码是合格的”；
2. 写完代码要跑什么命令才能“过门槛”；
3. 测试、React、TS 等关键技术栈的“家规”。

### 2. 对团队的启示

对我们这样规模的团队，关键不是“AI 会不会写代码”，而是：

> AI 能不能在**我们自己的工程规范之内**写代码，并且不会把每个项目变成“各写各的风格”。

Gemini CLI 的做法给出一个非常有操作性的模式：

- **项目级 GEMINI.md：让每个仓库都有自己的“Agent 使用说明”**
  - 内容不仅写给人，更写给 Agent：
    - 代码风格、架构边界、模块划分；
    - 依赖版本、推荐库（比如统一用哪版 Redis/消息队列/内部 SDK）；
    - 测试策略、必跑命令；
    - 与内部平台（监控、日志、配置中心、RPC 框架）的集成规范。
- **组织级模板**：
  - 在公司层面提供 GEMINI.md 模板：
    - 共性部分：代码风格、通用基础设施接入规范、日志/监控/安全要求；
    - 项目级扩展：各业务线可以追加自己的特殊要求。
- **与 Agent 集成**：
  - 让我们的 Agent 在每次进入仓库时，优先读取 GEMINI.md；
  - 在生成代码/修改代码前，根据 GEMINI.md 自动调整提示词和行为。

这相当于把「工程规范」从“文档”升级为“Agent 的长期记忆 + 行动约束系统”。

---

## 四、Checkpointing：先上安全网，再谈 AI 改代码

### 1. 机制概览：自动快照 + 一键 `/restore`

Gemini CLI 的 Checkpointing 功能做了几件关键事：

1. **触发时机**
   - 当用户批准任何会修改文件系统的工具（如 `write_file`、`replace` 等）时；
   - 在工具真正执行之前，自动创建 checkpoint。

2. **Checkpoint 包含什么**：
   - 一个影子 Git 仓里的 **Git snapshot**：
     - 存在 `~/.gemini/history/<project_hash>`，完全不污染用户真实仓库；
     - 通过 add/commit 把当前项目状态完整记录下来。
   - 完整的 **会话历史**（history + clientHistory）；
   - 即将执行的 **工具调用**（toolCall 名称 + 参数）；
   - 全部以 JSON 文件形式写入 `~/.gemini/tmp/<project_hash>/checkpoints`。

3. **恢复流程 `/restore`**：
   - 不带参数的
     `/restore`：列出当前项目所有 checkpoint 文件（按时间、文件名、工具名命名）；
   - 指定文件 `/restore <checkpoint_file>`：
     - 通过 GitService 把项目文件恢复到对应 commit；
     - 在 CLI 中重新加载会话历史；
     - 把原始工具调用重新抛给 UI，用户可以重新执行/修改/忽略。

一句话总结：**每次 AI 改写前，系统自动“拍快照”，用户随时可以一键回到之前的世界。**

### 2. 管理视角：它解决了管理者最关心的几件事

对于管理大规模研发团队的负责人，落地 AI 改代码经常有几个痛点：

1. **谁为错误修改负责？**
   - 有了影子 Git 仓的 checkpoint，每一次 AI 导致的代码变更都有“前后状态”；
   - 真出问题，可以快速还原、比对，工程师负担更小，责任也更可追踪。

2. **如何在现网项目上“敢用”AI？**
   - 引入 AI 之前先上 checkpoint 安全网；
   - 让团队知道“随时可一键还原”，显著降低心理阻力。

3. **怎么控制“瞎改一通”的风险？**
   - Checkpoint + `/restore` 强制任何“危险操作”都在可回滚的轨道上进行；
   - 更容易制定规则：比如在核心仓库，所有 AI 改动都必须在开启 checkpoint 的情况下操作。

### 3. 我们可以借鉴的设计原则

如果我们要在团队内部做自己的 Agent 或改造现有工具，可以直接复用几条原则：

1. **物理隔离的影子仓**：
   - 不污染业务 Git 仓；
   - 所有由 Agent 触发的快照都在独立仓记录，便于审计和回滚。

2. **工具执行前截断**：
   - 在“工具执行之前”强制生成 checkpoint；
   - 确保所有变更都有前镜像。

3. **与会话闭环存档**：
   - checkpoint 不只存文件状态，还要存对话上下文和工具调用；
   - 方便日后回溯“AI 为什么这么改”。

4. **用户级恢复体验简化**：
   - 提供类似 `/restore` 的一键命令；
   - 把恢复的复杂度从“高级 Git 操作”降到“普通用户也敢点”。

---

## 五、企业环境中的 Gemini CLI：把 Agent 放进“制度”和“基础设施”里

围绕 “Gemini CLI for the enterprise” 的内容，可以上升为一套组织视角的清单。

### 1. 配置集中化：统一 Agent 的“世界观”

- 通过系统级 `settings.json` 模板，集中控制：
  - 使用哪些模型/地区（避免每个人自己选，导致合规/成本不可控）；
  - 是否开启 checkpointing；
  - 默认超时、最大输出 token 等参数。
- 在企业镜像或配置管理系统中预置这些配置：
  - 新人或新环境拿到就是“公司认可的标准配置”。

### 2. 策略与权限：通过 Policy Engine 收紧边界

- 使用策略文件（如 `bundle/policies/*.toml`）实现：
  - 限制可调用的工具类别（只读场景禁止写入类工具）；
  - 限定可访问的目录范围（例如只允许改 `src/`，禁止改配置/部署/证书相关目录）；
  - 根据场景切换策略：
    - 审阅模式：仅 `list_directory`、`read_file`、`ripgrep` 之类工具；
    - 安全改写模式：允许写入，但必须在 checkpointing + 审批之下。

### 3. 凭证与网络：避免“每个人自己配一套秘钥”

- 在企业环境下统一：
  - HTTP(S) 代理、NO_PROXY 配置；
  - 服务账号和访问凭证；
- 将 CLI/Agent 运行在受控跳板机或容器里：
  - 减少凭证散落在个人终端；
  - 便于统一审计网络访问。

### 4. 审计与回滚：配合 checkpointing 实现“可追溯 AI”

- 除了影子 Git 仓快照外，还应：
  - 记录会话日志到 `~/.gemini/tmp/<hash>/logs.json` 等位置；
  - 通过 `/restore` 和日志结合，支持：
    - 复盘一次错误修改的整个过程；
    - 在极端场景下做事后审核。

### 5. 扩展管控：审核过的扩展才能进生产环境

- 将可用的 extensions 目录、`gemini-extension.json` 集中分发；
- 只允许经过安全与规范审核的扩展在企业环境内启用；
- 禁用未授权工具，避免“某个开发者随手写了个危险脚本，被所有人用”。

### 6. 分发方式：把 AI Agent 当作“企业工具链的一部分”

- 通过 CI/镜像统一提供：
  - 预装 Node/npm 依赖；
  - 带有预设 `settings.json`、策略文件、受控 extensions 的压缩包或容器镜像。
- 开发者只需要：
  - 解压或拉取镜像；
  - 就获得一套统一、合规的 Agent 能力。

---

## 六、Token 缓存与成本优化：在设计层面给费用上“闸门”

Gemini CLI 给出了一个系统化思路，我们可以直接借用。

### 1. 避免重复请求：多级缓存

- **系统提示 / 项目上下文片段缓存**：
  - 对于固定系统提示、固定项目规范片段（如 GEMINI.md）；
  - 在服务端做缓存，而不是每次完整发送；
- **问句 + 上下文组合幂等缓存**：
  - 对常见 FAQ 型问题，按「用户问句 + 关键项目上下文」作为键做缓存；
  - 命中后直接复用模型输出或用小模型复述。

### 2. 输入截断与压缩：只把“重要上下文”送给模型

- 对长对话历史：
  - 定期将早期多轮历史做“摘要 + 关键消息保留”；
  - 保留最近工具调用结果、用户决策，丢弃闲聊。
- 对大文件：
  - 先用 `ripgrep`/分块摘要选出相关片段；
  - 只把关键片段送入模型。

### 3. 流水线并行与请求合并

- 尽量并行地拉取必要信息：
  - 例如同时搜索相关文件、读取配置、查接口定义；
- 在 API 支持的情况下，将多个小请求合并；
- 通过并行 + 合并减少会话轮次，综合降低 token 消耗。

### 4. 模型分级：双模型路由

- 默认使用中档模型完成：
  - 搜索、路由、错误解释、简单代码改写等；
- 仅在以下场景切高阶模型：
  - 大段复杂重构、架构设计、协议设计等；
- 在 `settings.json` 中明确定义：
  - “默认模型” & “高阶模型”；
  - 并约束高阶模型的 max_output_tokens。

### 5. 输出限流与分段生成

- 降低默认 `max_output_tokens` 和温度；
- 对长文档生成采用分段策略：
  - 每段限定 token；
  - 根据用户确认决定是否继续生成下一段；
- 避免“一次性生成 20 页文档”这种成本失控场景。

### 6. 管理层可以推动的动作

- 建立简单的指标面板：
  - 每个团队 / 仓库 / Agent 的 token 使用量、命中缓存率；
- 制定配额和告警：
  - 例如单 Agent 单日 token 上限；
  - 超出前 80% 预警，提醒优化缓存/提示词。

---

## 七、Agent 架构模式：按场景选型，而不是“多代理=高级”

基于 Google Cloud “Choose a design pattern for your agentic AI
system”的经验法则，我们可以用简单的话帮你判断：

### 1. 单 Agent

- **适用场景**：
  - 需求清晰、上下文集中、工具少（≤3）；
  - 强调低延迟、可控输出；
- **典型例子**：
  - 一个本地“命令伴侣”：帮你生成 Git 命令、解释错误日志；
  - 简单的“代码改写助手”：在单一仓库里做小范围重构。

### 2. Multi-Agent（松耦合协作）

- **适用场景**：
  - 天然有几个不同的子任务（检索、规划、执行），但调度关系不复杂；
  - 强调多视角、召回能力；
- **典型例子**：
  - 知识库问答系统：
    - 检索 Agent 负责召回文档；
    - 生成 Agent 负责草稿；
    - 评审 Agent 做事实检查、选优。

### 3. Manager / Worker（层级模式）

- **适用场景**：
  - 需要动态分解任务、派单、验收；
  - 类似项目管理/任务分发；
- **典型例子**：
  - 代码改错流水线：
    - Manager 接受“修复线上问题”的自然语言需求；
    - 分配给：
      - 代码检索 Worker；
      - 修复候选方案生成 Worker；
      - 测试执行 Worker；
      - 评审 Worker。

### 4. Orchestration（流程编排 / DAG）

- **适用场景**：
  - 步骤、前后依赖关系明确，适合建成状态机或 DAG；
  - 强调可观测、可重试、可断点；
- **典型例子**：
  - 自动化 Bug Fix pipeline：
    1. 检索相关文件；
    2. 静态分析/运行测试；
    3. 生成修复代码；
    4. 自检（lint/test）；
    5. 评审 & 人工确认；
    6. 提交 PR。
  - 智能化 CI/CD：

### 5. 与我们团队典型场景的映射建议

- **代码 review / 重构助手**：
  - 可以从 **单 Agent** 起步；
  - 部分功能（如复杂重构）升级为 Manager + Worker。
- **知识库问答（问内部文档/接口/规范）**：
  - 更适合 **Multi-Agent + 评审**。
- **自动修复 CI 失败**：
  - 适合用 **Orchestration 模式**，嵌入现有 CI 流水线。
- **跨团队工程实践对齐（规范建议、风险提示）**：
  - Manager/Worker 模式可以把“规范检查”“架构评审”等拆成多个 Worker。

---
